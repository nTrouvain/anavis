{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import uuid\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from dateutil.parser import parse\n",
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_day(day, directory):\n",
    "    dir_names = [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]\n",
    "    \n",
    "    filenames = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    frames = []\n",
    "    for f_name in filenames:\n",
    "        if day in f_name:\n",
    "            file = gzip.open(f\"{directory}/{f_name}\", \"r\")\n",
    "            frames.append(pd.read_csv(file, sep=\";\"))\n",
    "    \n",
    "    df = pd.concat(frames)\n",
    "    df.Timestamp = pd.to_datetime(df.Timestamp)\n",
    "    df.index = df.Timestamp\n",
    "    df.drop([\"Timestamp\"], inplace=True, axis=1)\n",
    "    \n",
    "    # Problèmes avec les données \"clean\": plusieurs jours d'enregistrements sont contenus dans les fichiers\n",
    "    return df[df.index.day == datetime.datetime.strptime(day, '%Y-%m-%d').day].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    dir_names = [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]\n",
    "    \n",
    "    dfs = {}\n",
    "    for d_name in tqdm(dir_names, \"Directory\"):\n",
    "        filenames = [f for f in os.listdir(f\"{directory}/{d_name}\") if os.path.isfile(os.path.join(f\"{directory}/{d_name}\", f))]\n",
    "        station = {}\n",
    "        for f_name in filenames:\n",
    "            if station.get(f_name[:10]) is None:\n",
    "                station[f_name[:10]] = []\n",
    "                \n",
    "            file = gzip.open(f\"{directory}/{d_name}/{f_name}\", \"r\")\n",
    "            station[f_name[:10]].append(pd.read_csv(file, sep=\";\"))\n",
    "        \n",
    "        station = {date: pd.concat(dfs).to_dict() for date, dfs in station.items()}\n",
    "        dfs[d_name] = station\n",
    "        \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(data_dir=data_dir):\n",
    "    dfs = []\n",
    "    for d_name in tqdm(os.listdir(\"./clean/\")):\n",
    "        for f_name in os.listdir('./clean/' + d_name):\n",
    "            file = gzip.open(os.path.join(data_dir, d_name, f_name), \"r\")\n",
    "            dfs.append(pd.read_csv(file, sep=\";\"))\n",
    "\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    es.indices.delete(index=\"velos\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    es.indices.delete(index=\"velos_parma\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    es.indices.delete(index=\"velos_parma_test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_2016_data():\n",
    "    datas = []\n",
    "    data_index= \"velos\"\n",
    "    data_dir = \"clean/\"\n",
    "\n",
    "    for d_name in tqdm(os.listdir(\"./clean/\")):\n",
    "        for f_name in os.listdir(os.path.join(data_dir, d_name)):\n",
    "            file = gzip.open(os.path.join(data_dir, d_name, f_name), \"r\")\n",
    "            df = pd.read_csv(file, sep=\";\")\n",
    "            df[\"Timestamp\"] = df[\"Timestamp\"].apply(lambda x : parse(x).isoformat())\n",
    "            #df[\"Timestamp\"] = df[\"Timestamp\"].apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "            df[\"Station\"] = df[\"Station\"].apply(lambda station : station[4:])\n",
    "            df.columns = [c.lower() for c in df.columns]\n",
    "            \n",
    "            #date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                 \n",
    "            for _, row in df.iterrows():\n",
    "                if (row[\"timestamp\"] > parse(\"2016-01-01 00:00:00\").isoformat() and row[\"timestamp\"] < parse(\"2016-12-31 23:59:59\").isoformat()):\n",
    "                    datas.append('{ \"index\" : { \"_index\" : \"' + data_index +'\" } }')\n",
    "                    datas.append(row.to_json())\n",
    "                    if(len(datas) == 1000):\n",
    "                        es.bulk(datas)\n",
    "                        datas = []\n",
    "        break\n",
    "    if len(datas) > 0:\n",
    "        es.bulk(datas)\n",
    "        datas = []\n",
    "\n",
    "load_2016_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3814238\n",
      "\n",
      "\n",
      "\n",
      "             Timestamp  Station  Bikes  Slots  Total Status  Humidity  \\\n",
      "0  2015-04-22 11:50:00  01. Duc      2      4      6  clear      68.0   \n",
      "1  2015-04-22 12:00:00  01. Duc      2      4      6  clear      68.0   \n",
      "2  2015-04-22 12:10:00  01. Duc      2      4      6  clear      68.0   \n",
      "0  2017-04-09 01:20:00  01. Duc      7      3     10  Clear      71.0   \n",
      "0  2015-04-22 07:40:00  01. Duc      3      4      7  clear      53.0   \n",
      "\n",
      "   Pressure Rain  WindDeg  WindSpeed Snow  TemperatureTemp  \n",
      "0   1028.64   {}  292.501       2.01   {}            18.22  \n",
      "1   1028.64   {}  292.501       2.01   {}            18.22  \n",
      "2   1028.64   {}  292.501       2.01   {}            18.22  \n",
      "0   1022.00   {}  316.502       0.68   {}            14.00  \n",
      "0    958.22   {}  202.502       1.06   {}             6.81  \n",
      "\n",
      "\n",
      "\n",
      "987419\n",
      "\n",
      "\n",
      "\n",
      "             timestamp  station  bikes  slots  total  status  humidity  \\\n",
      "0  2016-09-22 09:00:00  01. Duc      5      4      9  clouds      26.0   \n",
      "1  2016-09-22 09:10:00  01. Duc      5      4      9  clouds      92.0   \n",
      "0  2016-04-06 02:50:00  01. Duc      2      8     10   clear      91.0   \n",
      "1  2016-04-06 03:00:00  01. Duc      2      8     10   clear      91.0   \n",
      "2  2016-04-06 03:10:00  01. Duc      2      8     10   clear      91.0   \n",
      "\n",
      "   pressure rain  winddeg  windspeed snow  temperaturetemp  \n",
      "0   1021.10   {}  233.503       1.21   {}            16.57  \n",
      "1   1020.00   {}  233.503       1.21   {}            15.99  \n",
      "0    943.82   {}  42.0004       1.06   {}             7.60  \n",
      "1    943.82   {}  42.0004       1.06   {}             7.60  \n",
      "2    943.82   {}  42.0004       1.06   {}             7.60  \n",
      "              timestamp     station  bikes  slots  total  status  humidity  \\\n",
      "8   2016-03-05 02:30:00  16. Toschi      3      7     10    rain     100.0   \n",
      "9   2016-03-05 02:40:00  16. Toschi      3      7     10    rain     100.0   \n",
      "10  2016-03-05 02:50:00  16. Toschi      3      7     10  clouds      61.0   \n",
      "11  2016-03-05 03:00:00  16. Toschi      3      7     10  clouds      61.0   \n",
      "12  2016-03-05 03:10:00  16. Toschi      3      7     10  clouds      91.0   \n",
      "\n",
      "    pressure          rain  winddeg  windspeed snow  temperaturetemp  \n",
      "8     935.09  {u'3h': 0.6}  179.501       1.31   {}             3.79  \n",
      "9     935.09  {u'3h': 0.6}  179.501       1.31   {}             3.79  \n",
      "10   1004.00            {}       60       3.60   {}             8.00  \n",
      "11   1004.00            {}       60       3.60   {}             8.00  \n",
      "12    932.65            {}  182.002       1.61   {}             2.59  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#dfs_light = dfs[(dfs['Timestamp'] > \"2016-01-01 00:00:00\") & (dfs['Timestamp'] < \"2016-12-31 23:59:59\")]\n",
    "#dfs_light.columns = [c.lower() for c in dfs.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': '2016-09-22 09:00:00', 'station': '01. Duc', 'bikes': 5, 'slots': 4, 'total': 9, 'status': 'clouds', 'humidity': 26.0, 'pressure': 1021.1, 'rain': '{}', 'winddeg': 233.503, 'windspeed': 1.21, 'snow': '{}', 'temperaturetemp': 16.57}\n"
     ]
    }
   ],
   "source": [
    "#for i, row in zip(range(1), dfs.iterrows()):\n",
    "#    print(row[1].WindDeg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "id = 1\n",
    "for row in dfs.iterrows():\n",
    "    for date, df in station_dic.items():\n",
    "        res = es.index(index=f\"velos\", id=id, body=df)\n",
    "        print(res['result'])\n",
    "        id += 1\n",
    "\"\"\"\n",
    "\n",
    "def gendata(dfs):\n",
    "    for index, row in dfs.iterrows():\n",
    "        for key, item in row[1].to_dict().items():\n",
    "            if item == \"None\":\n",
    "                row[1][key] = 0\n",
    "                \n",
    "        yield {\n",
    "            \"_id\": row[0],\n",
    "            \"_index\": \"velos\",\n",
    "            \"_type\": \"_doc\",\n",
    "            \"_source\": row[1].to_dict(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
